---
layout: about
title: About
permalink: /
subtitle: 

profile:
  align: right
  image: chau.jpeg
  image_circular: false # crops the image to make it circular
  more_info: >
    lhchau20 (at) apcs (dot) fitus (dot) edu (dot) vn
  

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I recently graduated from the Advanced Program in Computer Science at Ho Chi Minh City University of Science, Vietnam, one of the top undergraduate programs in Vietnam, under the supervision of Professor [Minh-Triet Tran](https://scholar.google.com/citations?hl=en&user=lt2ATkkAAAAJ&view_op=list_works&authuser=2&sortby=pubdate}). You can explore my [Publications](https://scholar.google.com/citations?user=j4ck-L4AAAAJ).

I am a hard-working and passionate student researcher working on fundamental problems in machine learning. My focus is on understanding why certain methods succeed and how their underlying mechanisms contribute to better generalization and robustness. To achieve this, I analyze simplified models to derive theoretical insights and validate them empirically on large-scale deep neural networks. By combining both perspectives, I aim to uncover key principles that improve the efficiency and reliability of deep learning methods. Currently, my work includes (but is not limited to):
1. **Generalization**: enhancing generalization and robustness on realistic datasets such as *out-of-distribution datasets*, *noisy labels*, and *imbalanced class datasets*, which are very common in real-world domains including medical imaging, autonomous driving, and natural language processing. Currently, I am focusing on analyzing the training dynamics of robust methods such as Sharpness-Aware Minimization to explore why and how they achieve robustness and to investigate new ways to enhance their abilities.
2. **Efficient AI**: knowledge distillation and quantization, compresses large DNNs (teacher) into smaller network (student). Currently, I am focusing on enhancing both *teacher quality* and the *distillation process* to obtain a better student model.
3. **LLMs and Diffusion models**: developing both theoretical and practical methods to enhance the performance of real-world applications.

I am seeking a funded MPhil/PhD position starting in 2025. If you are interested in my research, please feel free to contact me via email!