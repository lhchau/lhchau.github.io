---
layout: about
title: About
permalink: /
subtitle: Undergraduate from the Advanced Program in Computer Science (APCS), at <a>University of Science, Ho Chi Minh City</a>

profile:
  align: right
  image: chau.jpeg
  image_circular: false # crops the image to make it circular
  more_info: >
    lhchau20 (at) apcs (dot) fitus (dot) edu (dot) vn
  

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I recently graduated from the Advanced Program in Computer Science at the University of Science, Ho Chi Minh City, one of the top undergraduate programs in Vietnam. You can explore my [Publications](https://scholar.google.com/citations?user=j4ck-L4AAAAJ)

How can we enhance AI safety in practice? This fundamental question drives my research into the training dynamics of gradient-based methods. Training deep neural networks currently relies on simple gradient-based updates with the hope of finding generalizable minima. However, what if these methods fail and we discover that stochastic gradient descent (SGD) is not the ``master key"? In challenging scenarios such as noisy labels or out-of-distribution datasets, gradient-based methods often overfit to noise or introduce class biases.

Motivated by these challenges, my research focuses on exploring and understanding optimization dynamics to enhance model generalization and contribute to AI safety across diverse applications. As a first step in this direction, I characterized the behavior of perturbed gradients in Sharpness-Aware Minimization (SAM) under label noise settings. This work aims to improve generalization by slowing the fitting of noisy labels, laying the foundation for safer and more reliable AI systems. Currently, my work includes (but is not limited to):
1. **Model Robustness**: developing methods to improve neural networks' generalization on out-of-distribution datasets, noisy label datasets.
2. **Model Efficiency**: developing techniques to accelerate the training of neural networks.

I am seeking a PhD position starting in 2025. Please contact me through email if you are interested in my research!